{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    "import sagemaker\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.download_file('mltestdiego', 'SMSSpamCollection.csv', '/tmp/data.csv')\n",
    "\n",
    "vectors = []\n",
    "labels = []\n",
    "\n",
    "with open('/tmp/data.csv') as f:\n",
    "    content = f.readlines()\n",
    "    counter = 0\n",
    "    for line in content: \n",
    "        counter = counter + 1\n",
    "        text = line.split(\",\")\n",
    "        vectors.append(text[1])\n",
    "        labels.append(text[0])\n",
    "        # create the transform\n",
    "\n",
    "#vectorizer_vectors = TfidfVectorizer()\n",
    "#vectorizer_vectors.fit(vectors)\n",
    "\n",
    "#with open('/tmp/data.csv') as f:\n",
    "#    vector = vectorizer_vectors.transform(f)\n",
    "\n",
    "labels = np.asarray(labels).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5555, 87413)\n",
      "5555\n",
      "87413\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "       results[i, sequence] = 1. \n",
    "    return results\n",
    "\n",
    "    \n",
    "#populate dictionary    \n",
    "words = []\n",
    "for sms in vectors:\n",
    "    for word in text_to_word_sequence(sms):\n",
    "        words.append(word)\n",
    "\n",
    "data = [] \n",
    "# one hot encoding for each sentence\n",
    "for sms in vectors:\n",
    "    temp = one_hot(sms, len(words))\n",
    "    data.append(temp)\n",
    "\n",
    "\n",
    "#vectorize the all sms\n",
    "train = vectorize_sequences(data, len(words))\n",
    "print train.shape\n",
    "\n",
    "\n",
    "print len(data)\n",
    "print len(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5555, 87413)\n",
      "(4000, 87413)\n",
      "(1555, 87413)\n"
     ]
    }
   ],
   "source": [
    "train_labels = labels[:4000] \n",
    "test_labels = labels[4000:]\n",
    "\n",
    "print train.shape\n",
    "\n",
    "train_data = train[:4000] \n",
    "test_data = train[4000:]\n",
    "\n",
    "print train_data.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu',input_shape=(87413,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy']\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1555 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.6584 - acc: 0.8560 - val_loss: 0.6143 - val_acc: 0.9704\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5813 - acc: 0.9820 - val_loss: 0.5498 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.5153 - acc: 0.9880 - val_loss: 0.4898 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4521 - acc: 0.9897 - val_loss: 0.4318 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3929 - acc: 0.9905 - val_loss: 0.3782 - val_acc: 0.9826\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.3387 - acc: 0.9918 - val_loss: 0.3293 - val_acc: 0.9839\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2902 - acc: 0.9920 - val_loss: 0.2862 - val_acc: 0.9846\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2474 - acc: 0.9935 - val_loss: 0.2480 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.2099 - acc: 0.9938 - val_loss: 0.2148 - val_acc: 0.9852\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1775 - acc: 0.9942 - val_loss: 0.1865 - val_acc: 0.9852\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                   labels[:4000],\n",
    "                epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data=(test_data, labels[4000:])\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45844048]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sms = \"SIX chances to win CASH! From 100 to 20000 pounds txt> CSH11 and send to 87575. Cost 150p/day 6days 16+ TsandCs apply Reply HL 4 info\"\n",
    "sms = \"Call now and get 80% discount on your next pair of shoes! Call 8003344555 and get all CASH you need\"\n",
    "\n",
    "sentence = one_hot(sms, len(words))\n",
    "\n",
    "sentences = [sentence]\n",
    "\n",
    "vector = vectorize_sequences(sentences,len(words))\n",
    "\n",
    "\n",
    "result = model.predict(vector)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save_weights('/tmp/my_sms_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/tmp/sms_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.5 KiB/1.5 KiB (27.6 KiB/s) with 1 file(s) remaining\r",
      "upload: ../../../tmp/sms_model.json to s3://mltestdiego/sms/sms_model.json\n"
     ]
    }
   ],
   "source": [
    "%%bash    \n",
    "aws s3 cp /tmp/sms_model.json s3://mltestdiego/sms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/5.4 MiB (3.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 512.0 KiB/5.4 MiB (6.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 768.0 KiB/5.4 MiB (9.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 1.0 MiB/5.4 MiB (12.1 MiB/s) with 1 file(s) remaining \r",
      "Completed 1.2 MiB/5.4 MiB (14.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 1.5 MiB/5.4 MiB (17.1 MiB/s) with 1 file(s) remaining \r",
      "Completed 1.8 MiB/5.4 MiB (19.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.0 MiB/5.4 MiB (20.2 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.2 MiB/5.4 MiB (22.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.5 MiB/5.4 MiB (24.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.8 MiB/5.4 MiB (26.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.0 MiB/5.4 MiB (28.3 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.2 MiB/5.4 MiB (30.2 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.5 MiB/5.4 MiB (32.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.8 MiB/5.4 MiB (33.8 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.0 MiB/5.4 MiB (35.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.2 MiB/5.4 MiB (37.3 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.5 MiB/5.4 MiB (39.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.8 MiB/5.4 MiB (40.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.0 MiB/5.4 MiB (42.2 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.2 MiB/5.4 MiB (43.7 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.4 MiB/5.4 MiB (5.7 MiB/s) with 1 file(s) remaining  \r",
      "upload: ../../../tmp/my_sms_model_weights.h5 to s3://mltestdiego/sms/my_sms_model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 cp /tmp/my_sms_model_weights.h5 s3://mltestdiego/sms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open(\"/tmp/sms_model.json\", \"w\") as json_file:\n",
    "    model2test = model_from_json(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -c 'import keras; print(keras.__version__)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
